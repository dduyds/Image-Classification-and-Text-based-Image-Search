import streamlit as st

# Page configuration
st.set_page_config(
    page_title="Home",
    page_icon="ğŸ ",
    layout="centered"
)

# Main title
st.title("ğŸ“¦ CLIP Application on CIFAR-10")
st.markdown("---")

# Introduction
st.markdown("""
## ğŸ‘‹ Introduction

Welcome to the demo application of a **custom CLIP model** trained on the **CIFAR-10** dataset!

This app allows you to:
- ğŸ·ï¸ **Classify images** from the CIFAR-10 test set with 10 basic categories.
- ğŸ” **Search for similar images** based on textual descriptions (captions) using **similarity** between embeddings.

---

## ğŸ”§ Technologies Used
- [x] Build and custom CLIP model (PyTorch)
- [x] CIFAR-10 dataset (10,000 test images)
- [x] Lightweight, user-friendly UI with Streamlit

---

## ğŸ“‚ Navigation
Use the **left sidebar** to access different functionalities:
- ğŸ‘‰ **Image Classification**
- ğŸ‘‰ **Image Search by Caption**

---

## ğŸ“˜ About CLIP
CLIP (Contrastive Languageâ€“Image Pretraining) is a model that learns joint embeddings of images and text into a **shared vector space**, enabling cross-modal retrieval between images and captions.
""")

# Footer
st.markdown("---")